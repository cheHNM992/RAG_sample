{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストコーパスをチャンクに分割\n",
    "with open('code_gate.py', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# コードに特化したスプリッターを使用（Pythonコードの場合）\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=500,  # コード理解に適したサイズ\n",
    "    chunk_overlap=50  # 適度なオーバーラップで文脈を保持\n",
    ")\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッセージのベクトル化\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# コードに特化したエンベディングモデルを使用\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-m3',  # 多言語対応で高性能なエンベディングモデル\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96659421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# データベースの保存\n",
    "db = FAISS.from_texts(texts, embeddings)\n",
    "db.save_local('code.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 保存したデータベースの読み込み\n",
    "db = FAISS.load_local('code.db', embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12caa754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieverの設定 - 適切なパラメータで検索精度を向上\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # Maximum Marginal Relevanceで多様性のある検索結果を得る\n",
    "    search_kwargs={\n",
    "        \"k\": 5,  # 取得するドキュメント数\n",
    "        \"fetch_k\": 20,  # MMR探索用の初期取得数\n",
    "        \"lambda_mult\": 0.7  # 関連性と多様性のバランス (0.0-1.0)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの準備\n",
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-*****'\n",
    "\n",
    "openai_llm = ChatOpenAI(model_name=\"gpt-4.1\")\n",
    "#openai_llm = ChatOpenAI(model_name=\"gpt-4.1-nano\")\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=openai_llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c71925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行例\n",
    "q = \"どんなプログラミング言語で書かれていますか？\"\n",
    "ans = qa.invoke(q)\n",
    "print(q)\n",
    "print(ans['result'])\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "q = \"定義されている関数を全てリストアップして下さい\"\n",
    "ans = qa.invoke(q)\n",
    "print(q)\n",
    "print(ans['result'])\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "q = \"AND関数は何回呼ばれますか？\"\n",
    "ans = qa.invoke(q)\n",
    "print(q)\n",
    "print(ans['result'])\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "q = \"このプログラムがやっていることは何ですか？\"\n",
    "ans = qa.invoke(q)\n",
    "print(q)\n",
    "print(ans['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
